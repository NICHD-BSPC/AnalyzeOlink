---
title: "Parametric Assumption Violation Analysis"
author: "NICHD Bioinformatics and Scientific Programming Core"
output:
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
    toc_depth: 3
params:
  npx_data:        NULL
  sampletable:     NULL
  data:            NULL
---

# Analysis Overview

This report summarizes parametric assumption checks for the Olink PEA NPX
analyses. We assess:

- **Residual normality:** Shapiro–Wilk (SW) and Anderson–Darling (AD)
- **Variance homogeneity:** two‑sample F‑tests (FT)
- **Influence of outliers:** QQ plots + residual outlier frequencies

With the shipped **test data**, the primary contrast is **Group (disease vs control)**,
adjusting for `Cov1` and `Cov2`.

With real user data, you can tune which contrasts are assessed and the
outlier‑calling behavior in the **USER SETTINGS** block below.

```{r AnaylzeOlink, eval=FALSE, results='hide'}
# When running interactively, and not from the Snakefile,
# load the AnalyzeOlink R package, which is stored locally.
# This package has many custom functions used throughout this document.
devtools::document('../../AnalyzeOlink')
devtools::load_all('../../AnalyzeOlink')
```

```{r setup, include=FALSE}
library(dplyr)
library(purrr)
library(AnalyzeOlink)

# Read config
config <- yaml::read_yaml("../config/config.yaml")

# Set up cache invalidation
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  cache.extra = list(
    file.info("../config/config.yaml")$mtime,
    file.info(config$input_data_paths$PEA)$mtime,
    file.info(config$sampletable_paths$PEA)$mtime,
    file.info(config$output_data_paths$PEA)$mtime
  )
)

# Use Snakemake inputs if running via Snakefile; otherwise fall back to config
if (!is.null(params$npx_data)) {
  config$input_data_paths$PEA <- params$npx_data
}
if (!is.null(params$sampletable)) {
  config$sampletable_paths$PEA <- params$sampletable
}
if (!is.null(params$data)) {
  config$output_data_paths$PEA <- params$data
}
```

```{r fetch-data-from-olinkanalyze, results='asis', eval=TRUE, cache=TRUE}
olink_analyze_data <- readRDS(config$output_data_paths$PEA)
se_list            <- olink_analyze_data$se_list
res_list           <- olink_analyze_data$res_list
```

```{r subset-res-list, eval=TRUE, cache=TRUE, dependson='fetch-data-from-olinkanalyze'}
# Keep statistics for primary effects only
# (with test data this is Group for disease_vs_control)
res_list_subset_1_effect <- keep_primary_effects(res_list)
```

# Assumption‑check Settings (USER‑CONFIGURABLE)

Most users only need to edit this block.

```{r assumptions-user-settings, cache=FALSE}
# -------------------------------------------------------------------------
# USER SETTINGS
# -------------------------------------------------------------------------

# 1) Which contrasts should be assessed?
#    - NULL = assess all contrasts in res_list_subset_1_effect
#    - OR set a character vector of contrast names
contrasts_to_check <- c("disease_vs_control_anova")

# 2) Outlier frequency settings, Tukey IQR rule on residuals to define outliers
#    We count residual outliers only among proteins with SW p in this range.
pval_bin <- c(0, 0.1)
k        <- 1.5  # Tukey fence multiplier for outlier detection

# 3) How many QQ plots to show
num_proteins <- 10
num_samples  <- 10
```

```{r apply-user-settings, cache=TRUE, dependson=c('subset-res-list','assumptions-user-settings')}
if (!is.null(contrasts_to_check)) {
  bad <- setdiff(contrasts_to_check, names(res_list_subset_1_effect))
  if (length(bad) > 0) {
    stop("Unknown contrasts in contrasts_to_check: ", paste(bad, collapse = ", "))
  }
  res_list_subset_1_effect <- res_list_subset_1_effect[contrasts_to_check]
}
```

## Assess Normality

### Raw NPX Histogram {.tabset}

We observe non‑Gaussian raw NPX distributions, which is expected; what matters
is that **model residuals** are approximately normal.

```{r npx-histogram, results='asis', eval=TRUE, cache=FALSE, dependson='apply-user-settings'}
npx_hist(
  res_list_subset_1_effect,
  se_list,
  config$output_paths$assumptions_pea$plots,
  breaks = 100
)
```

### Residuals: Shapiro–Wilk p‑value histogram {.tabset}

Shapiro–Wilk (SW) tests residual normality per protein. Left‑skewed p‑value
histograms indicate departures from normality; here, these arise mostly from
heavy tails in a few samples, not global misspecification.

```{r sw-histogram, results='asis', eval=TRUE, cache=FALSE, dependson='apply-user-settings'}
normal_summary_table <- norm_hist(
  res_list_subset_1_effect,
  test   = "SW",
  alpha  = config$alpha,
  outdir = config$output_paths$assumptions_pea$plots,
  breaks = 20
)
```

### Residuals: Anderson–Darling p‑value histogram {.tabset}

Anderson–Darling (AD) is another way to test for abnormal residual error distributions.

```{r ad-histogram, results='asis', eval=TRUE, cache=FALSE, dependson='apply-user-settings'}
norm_hist(
  res_list_subset_1_effect,
  test   = "AD",
  alpha  = config$alpha,
  outdir = config$output_paths$assumptions_pea$plots,
  breaks = 20
)
```

### Variance homogeneity: F‑test p‑value histogram {.tabset}

Two‑sample F‑tests (per protein) flag unequal variances in a subset only,
suggesting limited heteroscedasticity impact.

```{r ft-histogram, results='asis', eval=TRUE, cache=FALSE, dependson='apply-user-settings'}
norm_hist(
  res_list_subset_1_effect,
  test   = "FT",
  alpha  = config$alpha,
  outdir = config$output_paths$assumptions_pea$plots,
  breaks = 20
)
```

```{r qq-outliers-list, results='asis', eval=TRUE, cache=TRUE, dependson='apply-user-settings'}
# Get per‑contrast, per‑protein outlier IDs (Tukey IQR rule on residuals)
outlier_list <- write_outlier_frequency_table(
  res_list_subset_1_effect,
  outdir      = config$output_paths$assumptions_pea$plots,
  pval_bin    = pval_bin,
  k           = k,
  print_plot  = FALSE
)
```

### Residuals: QQ Plots (per‑protein) {.tabset}

Per‑protein QQ plots clarify how residuals deviate. In typical real datasets,
departures are driven by **heavy tails or a few extreme samples** rather than
global misspecification.

```{r qq-residuals-proteins, results='asis', eval=TRUE, cache=TRUE, dependson='qq-outliers-list'}
plot_qq(
  res_list_subset_1_effect,
  outdir       = config$output_paths$assumptions_pea$plots,
  label_map    = outlier_list,
  num_proteins = num_proteins,
  type         = "protein"
)
```

### Residuals: Outlier Frequencies {.tabset}

Histogram counts how often each sample is flagged as a residual outlier among
proteins with SW p in `r paste0("[", pval_bin[1], ", ", pval_bin[2], "]")`.
This highlights consistently misbehaving samples. Sensitivity analyses
(and Cook’s distances) indicate whether removing such samples would materially
alter conclusions.

```{r qq-outliers-plot, results='asis', eval=TRUE, cache=TRUE, dependson='apply-user-settings'}
freq_tbl_list <- write_outlier_frequency_table(
  res_list_subset_1_effect,
  outdir      = config$output_paths$assumptions_pea$plots,
  pval_bin    = pval_bin,
  k           = k,
  print_plot  = TRUE
)
```

### Residuals: QQ Plots (per‑sample) {.tabset}

We examine QQ plots for the `r num_samples` samples most frequently flagged as
outliers; patterns again reflect a few extreme points rather than global
non‑normality.

```{r qq-residuals-samples, results='asis', eval=TRUE, cache=TRUE, dependson='qq-outliers-list'}
plot_qq(
  res_list_subset_1_effect,
  outdir       = config$output_paths$assumptions_pea$plots,
  label_map    = outlier_list,
  num_samples  = num_samples,
  num_proteins = num_proteins,
  type         = "sample",
  freq_table   = freq_tbl_list
)
```

```{r record-standard-assumption-violations, eval=TRUE, cache=TRUE, dependson='apply-user-settings'}
# Record residual normality (SW) and equal-variance (FT) multiple-testing results
sw_list <- record_standard_assumption_violations(res_list_subset_1_effect, "SW_padj")
ft_list <- record_standard_assumption_violations(res_list_subset_1_effect, "FT_padj")
```

## Session Information

```{r sessioninfo, eval=TRUE}
sessionInfo()
```
